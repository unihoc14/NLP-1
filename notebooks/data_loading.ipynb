{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: datasets in c:\\nlp_1\\.venv\\lib\\site-packages (3.3.2)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\nlp_1\\.venv\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\nlp_1\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: fsspec in c:\\nlp_1\\.venv\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\nlp_1\\.venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\nlp_1\\.venv\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\nlp_1\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\nlp_1\\.venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\nlp_1\\.venv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\nlp_1\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\nlp_1\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\nlp_1\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\nlp_1\\.venv\\lib\\site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\nlp_1\\.venv\\lib\\site-packages (from datasets) (0.29.1)\n",
      "Requirement already satisfied: packaging in c:\\nlp_1\\.venv\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\nlp_1\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\nlp_1\\.venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\nlp_1\\.venv\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\nlp_1\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\nlp_1\\.venv\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\nlp_1\\.venv\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\nlp_1\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\nlp_1\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\nlp_1\\.venv\\lib\\site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\nlp_1\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\nlp_1\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\nlp_1\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\nlp_1\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\nlp_1\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\nlp_1\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\nlp_1\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\nlp_1\\.venv\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\nlp_1\\.venv\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\nlp_1\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached torch-2.6.0-cp310-cp310-win_amd64.whl (204.2 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, joblib, click, nltk, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.2 click-8.1.8 jinja2-3.1.6 joblib-1.4.2 mpmath-1.3.0 networkx-3.4.2 nltk-3.9.1 sympy-1.13.1 torch-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch datasets nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\nlp_1\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jonas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispiel-Batch: ([['the', 'air', 'conditioning', 'went', 'out', 'during', 'a', 'film', 'and', 'the', 'clientele', 'walked', 'out', 'due', 'to', 'discomfort', 'what', 'were', 'they', 'leaving', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['yesterday', 'there', 'was', 'heavy', 'rain', 'and', 'theres', 'water', 'standing', 'everywhere', 'but', 'its', 'coming', 'down', 'hard', 'again', 'and', 'this', 'time', 'its', 'cold', 'what', 'sort', 'of', 'storm', 'is', 'it', 'now'], ['where', 'is', 'a', 'good', 'place', 'to', 'sore', 'a', 'wind', 'instrument', 'in', 'you', 'home', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['what', 'would', 'killing', 'people', 'make', 'one', 'of', 'your', 'victims', 'do', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['where', 'do', 'young', 'boys', 'hide', 'dirty', 'magazines', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['if', 'i', 'need', 'to', 'use', 'a', 'paper', 'clip', 'to', 'hold', 'medical', 'papers', 'together', 'where', 'would', 'i', 'be', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['where', 'would', 'you', 'find', 'a', 'sign', 'with', 'some', 'people', 'lined', 'up', 'next', 'to', 'it', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['what', 'can', 'sitting', 'in', 'a', 'room', 'waiting', 'for', 'an', 'appointment', 'lead', 'to', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['after', 'buying', 'products', 'reading', 'the', 'manual', 'enables', 'what', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['john', 'was', 'glad', 'that', 'he', 'had', 'help', 'the', 'piano', 'was', 'what', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['when', 'you', 'drive', 'you', 'may', 'have', 'to', 'stop', 'if', 'someone', 'is', 'doing', 'what', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['what', 'is', 'required', 'for', 'someone', 'to', 'win', 'when', 'competing', 'against', 'someone', 'else', 'in', 'ball', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['what', 'happens', 'to', 'someone', 'wading', 'while', 'fishing', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['the', 'police', 'didnt', 'pay', 'any', 'favors', 'their', 'job', 'was', 'to', 'what', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['where', 'did', 'he', 'put', 'the', 'newspaper', 'for', 'his', 'new', 'puppys', 'leaks', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['a', 'man', 'wanted', 'to', 'find', 'the', 'united', 'states', 'on', 'a', 'visual', 'where', 'should', 'he', 'look', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']], [[['house', '<PAD>'], ['offices', '<PAD>'], ['book', 'store'], ['car', '<PAD>'], ['movie', 'theatre']], [['blizzard'], ['hurricane'], ['cactus'], ['ocean'], ['drowning']], [['under', 'bed'], ['symphony', '<PAD>'], ['music', 'room'], ['band', 'practice'], ['music', 'store']], [['prison', 'sentence', '<PAD>'], ['sadness', '<PAD>', '<PAD>'], ['murder', '<PAD>', '<PAD>'], ['feelings', 'of', 'guilt'], ['die', '<PAD>', '<PAD>']], [['library'], ['drawer'], ['dentist'], ['bed'], ['airport']], [['desk', 'drawer'], ['file', 'folder'], ['office', '<PAD>'], ['hospital', '<PAD>'], ['file', 'cabinet']], [['bus', 'stop', '<PAD>', '<PAD>'], ['street', 'corner', '<PAD>', '<PAD>'], ['roadblock', '<PAD>', '<PAD>', '<PAD>'], ['fast', 'food', 'drive', 'thru'], ['city', '<PAD>', '<PAD>', '<PAD>']], [['impatience', '<PAD>', '<PAD>', '<PAD>'], ['have', 'fun', '<PAD>', '<PAD>'], ['boredom', '<PAD>', '<PAD>', '<PAD>'], ['giving', 'birth', 'to', 'frogs'], ['wisdom', '<PAD>', '<PAD>', '<PAD>']], [['understand', 'details', '<PAD>', '<PAD>'], ['being', 'able', 'to', 'use'], ['loss', 'of', 'money', '<PAD>'], ['economic', 'boom', '<PAD>', '<PAD>'], ['spending', 'money', '<PAD>', '<PAD>']], [['cranky'], ['peevish'], ['heavy'], ['difficult'], ['regretful']], [['while', 'driving'], ['check', 'mirrors'], ['walking', '<PAD>'], ['stop', '<PAD>'], ['passenger', '<PAD>']], [['edge', '<PAD>', '<PAD>'], ['skill', '<PAD>', '<PAD>'], ['luck', '<PAD>', '<PAD>'], ['challenge', '<PAD>', '<PAD>'], ['desire', 'to', 'win']], [['happiness', '<PAD>'], ['getting', 'drunk'], ['anger', '<PAD>'], ['wet', 'clothes'], ['catching', 'fish']], [['force', 'law'], ['board', 'vessels'], ['arrest', '<PAD>'], ['arm', 'weapons'], ['direct', 'traffic']], [['floor', '<PAD>'], ['jail', '<PAD>'], ['next', 'door'], ['library', '<PAD>'], ['porch', '<PAD>']], [['history', 'book'], ['atlas', '<PAD>'], ['tv', 'channels'], ['northern', 'hemisphere'], ['map', '<PAD>']]], tensor([4, 0, 2, 4, 3, 3, 0, 2, 1, 2, 2, 1, 3, 0, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Tokenizer-Funktion\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Tokenization und Bereinigung der Texte.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Satzzeichen entfernen\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Padding-Funktion für dynamisches Padding innerhalb eines Batches\n",
    "def pad_sequences(sequences, pad_token=\"<PAD>\"):\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    return [seq + [pad_token] * (max_length - len(seq)) for seq in sequences]\n",
    "\n",
    "class CommonsenseQADataset(Dataset):\n",
    "    def __init__(self, split=\"train\"):\n",
    "        self.dataset = load_dataset(\"commonsense_qa\")[split]\n",
    "        self.processed_data = self.process_data()\n",
    "    \n",
    "    def process_data(self):\n",
    "        \"\"\"Fragen und Antwortmöglichkeiten verarbeiten.\"\"\"\n",
    "        processed = []\n",
    "        for item in self.dataset:\n",
    "            question = preprocess_text(item[\"question\"])\n",
    "            choices = [preprocess_text(choice) for choice in item[\"choices\"][\"text\"]]\n",
    "            answer = ord(item[\"answerKey\"]) - ord('A')  # Antwort in Index umwandeln\n",
    "            processed.append((question, choices, answer))\n",
    "        return processed\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.processed_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.processed_data[idx]\n",
    "\n",
    "# Collate-Funktion für den DataLoader\n",
    "def collate_fn(batch):\n",
    "    questions, choices, answers = zip(*batch)\n",
    "    questions_padded = pad_sequences(questions)\n",
    "    choices_padded = [pad_sequences(choice_list) for choice_list in choices]\n",
    "    return questions_padded, choices_padded, torch.tensor(answers)\n",
    "\n",
    "# Datenlade-Funktion mit Padding\n",
    "def load_data(batch_size=16):\n",
    "    \"\"\"Lädt die Daten und gibt DataLoader zurück.\"\"\"\n",
    "    train_dataset = CommonsenseQADataset(\"train\")\n",
    "    val_dataset = CommonsenseQADataset(\"validation\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "# Testlauf\n",
    "if __name__ == \"__main__\":\n",
    "    train_loader, val_loader = load_data()\n",
    "    for batch in train_loader:\n",
    "        print(\"Beispiel-Batch:\", batch)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beispiel-Batch: ([['older', 'stars', 'collect', 'in', 'groups', 'called', 'what', 'on', 'the', 'outer', 'regions', 'of', 'a', 'galaxy', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['what', 'is', 'served', 'with', 'dinner', 'at', 'a', 'french', 'restaurant', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['denny', 'couldnt', 'find', 'his', 'hairbrush', 'he', 'looked', 'everywhere', 'for', 'it', 'under', 'and', 'over', 'up', 'and', 'down', 'it', 'was', 'not', 'where', 'he', 'thought', 'it', 'would', 'be', 'so', 'he', 'closed', 'the', 'door', 'behind', 'him', 'and', 'continued', 'his', 'systematic', 'search', 'where', 'might', 'denny', 'have', 'looked', 'first'], ['where', 'could', 'you', 'be', 'if', 'you', 'are', 'sit', 'quietly', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['as', 'the', 'man', 'descended', 'the', 'mountains', 'into', 'the', 'marsh', 'where', 'was', 'he', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['where', 'is', 'known', 'for', 'powerful', 'storms', 'from', 'the', 'ocean', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['while', 'chatting', 'with', 'friends', 'for', 'hours', 'what', 'did', 'the', 'formerly', 'lonely', 'man', 'feel', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['the', 'double', 'edged', 'razor', 'was', 'used', 'to', 'cut', 'tape', 'it', 'was', 'found', 'in', 'what', 'box', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['john', 'wanted', 'to', 'meet', 'interesting', 'people', 'but', 'he', 'always', 'drove', 'them', 'away', 'he', 'felt', 'that', 'he', 'needed', 'to', 'be', 'more', 'what', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['billy', 'loved', 'having', 'food', 'but', 'he', 'didnt', 'like', 'the', 'consequences', 'of', 'overeating', 'what', 'is', 'the', 'longterm', 'consequence', 'of', 'having', 'too', 'much', 'food', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['where', 'are', 'people', 'likely', 'to', 'push', 'a', 'religious', 'tract', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['where', 'is', 'a', 'famous', 'basketball', 'court', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['old', 'cowboy', 'and', 'indians', 'movies', 'always', 'have', 'a', 'horse', 'they', 'also', 'usually', 'take', 'place', 'in', 'what', 'region', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['john', 'spent', 'his', 'days', 'planting', 'ficus', 'trees', 'he', 'did', 'so', 'because', 'trees', 'were', 'an', 'important', 'part', 'of', 'what', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['james', 'needed', 'the', 'tools', 'now', 'he', 'wished', 'he', 'had', 'remembered', 'to', 'pack', 'them', 'when', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['what', 'do', 'you', 'end', 'up', 'with', 'after', 'cooking', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']], [[['night', 'sky'], ['black', 'hole'], ['globular', 'cluster'], ['press', 'conference'], ['heavens', '<PAD>']], [['montreal'], ['quebec'], ['manhattan'], ['potpourri'], ['wine']], [['house'], ['kitchen'], ['car'], ['drugstore'], ['bedroom']], [['sit', 'down'], ['lay', 'down'], ['alone', '<PAD>'], ['go', 'home'], ['meditate', '<PAD>']], [['louisiana', '<PAD>'], ['florida', '<PAD>'], ['everglades', '<PAD>'], ['field', '<PAD>'], ['low', 'lands']], [['rain', '<PAD>'], ['weather', 'report'], ['tropics', '<PAD>'], ['summer', '<PAD>'], ['america', '<PAD>']], [['happiness'], ['tiredness'], ['communication'], ['agreement'], ['answers']], [['drug', 'store', '<PAD>'], ['medicine', 'cabinet', '<PAD>'], ['first', 'aid', 'kit'], ['shaving', 'kit', '<PAD>'], ['shower', '<PAD>', '<PAD>']], [['understand', 'themselves'], ['socialize', '<PAD>'], ['take', 'class'], ['explore', '<PAD>'], ['friendly', '<PAD>']], [['digesting', '<PAD>'], ['constipation', '<PAD>'], ['weight', 'gain'], ['not', 'hungry'], ['gas', '<PAD>']], [['public', 'place', '<PAD>'], ['airport', '<PAD>', '<PAD>'], ['churchs', 'track', 'rack'], ['laundromat', '<PAD>', '<PAD>'], ['stage', '<PAD>', '<PAD>']], [['high', 'school', 'gymnasium'], ['use', '<PAD>', '<PAD>'], ['stadium', '<PAD>', '<PAD>'], ['city', '<PAD>', '<PAD>'], ['los', 'angeles', '<PAD>']], [['canada', '<PAD>'], ['triple', 'crown'], ['england', '<PAD>'], ['american', 'southwest'], ['kentucky', 'derby']], [['tropical', 'rainforest'], ['ecosphere', '<PAD>'], ['sunny', 'window'], ['pots', '<PAD>'], ['dirt', '<PAD>']], [['later', '<PAD>'], ['other', 'time'], ['tomorrow', '<PAD>'], ['then', '<PAD>'], ['broke', '<PAD>']], [['full', 'feast'], ['cooked', 'food'], ['having', 'dinner'], ['get', 'food'], ['pride', '<PAD>']]], tensor([2, 4, 4, 2, 4, 2, 0, 2, 4, 2, 0, 4, 3, 1, 3, 1]))\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = load_data()\n",
    "for batch in train_loader:\n",
    "    print(\"Beispiel-Batch:\", batch)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
